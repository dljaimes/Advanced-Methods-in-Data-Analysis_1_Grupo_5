{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boceto E13\n",
    "\n",
    "\n",
    "## Comentarios a discutir:\n",
    "1. Como interpretan la pergunta 'Analyze the writing patterns of each student'?, seria algo tipo hacer un top de palabras por estudiante?\n",
    "2. Para la tokenización \"entrené\" y llevé a matrices cada columna de preguntas por aparte, suponiendo que las pabaras que fueron importantes en el contexto de una pregunta pueden no serlo en el contexto de otra.\n",
    "3. Hay que predecir sector laboral, pero tiene bastantes valores unicos, a fuerza definí 3 grupos, podemos conversarlos.\n",
    "4. De cara a los modelos y al 'CountVectorizer' tenemos bastantes opciones donde calibrar hiperparametros, dado el tema de fechas de entrega y otros pendientes que tanto queremos profundizar?\n",
    "\n",
    "\n",
    "# Exercise 13\n",
    "\n",
    "The result will be evaluated from a report in Jupyter, which must be found in a public GitHub repository. The project must be carried out in the groups assigned in class. Use clear and rigorous procedures. Due date: July 29, 2021, 11:59 am (NOON), through Bloque Neón + (Upload repository link).\n",
    "\n",
    "## Analyze class homeworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sebtc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.tree import DecisionTreeClassifier     \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.corpus.stopwords.words('spanish')\n",
    "nltk.download('wordnet') \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Datasets/Consolidado_respuestas_escribir_v2.xlsx')\n",
    "data.columns = ['ID', 'Genero', 'Pregrado', 'Sector_trabajo','Edad','E1','E4','E6','E8','E10','E12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "E1_text = data['E1'].fillna(\"Sin texto\")\n",
    "E4_text = data['E4'].fillna(\"Sin texto\")\n",
    "E6_text = data['E6'].fillna(\"Sin texto\")\n",
    "E8_text = data['E8'].fillna(\"Sin texto\")\n",
    "E10_text = data['E10'].fillna(\"Sin texto\")\n",
    "E12_text = data['E12'].fillna(\"Sin texto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M    28\n",
      "F    10\n",
      "Name: Genero, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Genero'].value_counts())\n",
    "y_genero = data['Genero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financiero    24\n",
      "Otros          9\n",
      "Ingenieria     5\n",
      "Name: Sector_trabajo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['Sector_trabajo']=data['Sector_trabajo'].str.lower()\n",
    "data['Sector_trabajo']=np.where(data['Sector_trabajo'].str.contains('fin|banc'),'Financiero',data['Sector_trabajo'])\n",
    "data['Sector_trabajo']=np.where(data['Sector_trabajo'].str.contains('eléc|comu|estructu|ingen|oper'),'Ingenieria',data['Sector_trabajo'])\n",
    "data['Sector_trabajo']=np.where(data['Sector_trabajo'].str.contains('Fin|Ingen'),data['Sector_trabajo'],'Otros')\n",
    "print(data['Sector_trabajo'].value_counts())\n",
    "y_sector = data['Sector_trabajo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def split_into_lemmas(text):\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    return [wordnet_lemmatizer.lemmatize(word,pos='v') for word in words]\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "vect = CountVectorizer(ngram_range=(1,2),lowercase=True,stop_words=spanish_stopwords,max_features=100,min_df=2)#,analyzer=split_into_lemmas,)\n",
    "#vect = TfidfVectorizer(analyzer=split_into_lemmas,ngram_range=(1,5),lowercase=True,stop_words=spanish_stopwords),max_features=100,min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38, 100), (38, 100), (38, 100), (38, 100), (38, 100), (38, 100))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(E1_text)\n",
    "E1_text_dtm = vect.transform(E1_text)\n",
    "vect.fit(E4_text)\n",
    "E4_text_dtm = vect.transform(E4_text)\n",
    "vect.fit(E6_text)\n",
    "E6_text_dtm = vect.transform(E6_text)\n",
    "vect.fit(E8_text)\n",
    "E8_text_dtm = vect.transform(E8_text)\n",
    "vect.fit(E10_text)\n",
    "E10_text_dtm = vect.transform(E10_text)\n",
    "vect.fit(E12_text)\n",
    "E12_text_dtm = vect.transform(E12_text)\n",
    "#variables predictoras\n",
    "E1_text_dtm.shape,E4_text_dtm.shape,E6_text_dtm.shape,E8_text_dtm.shape,E10_text_dtm.shape,E12_text_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 600)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_pred=np.c_[E1_text_dtm.todense(),E4_text_dtm.todense(),E6_text_dtm.todense(),E8_text_dtm.todense(),E10_text_dtm.todense(),E12_text_dtm.todense()]\n",
    "tokens_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13.1\n",
    "\n",
    "Analyze the writing patterns of each student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13.2\n",
    "\n",
    "Create a classifier to predict the gender of each student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      0.733333\n",
       "std       0.035136\n",
       "min       0.666667\n",
       "25%       0.750000\n",
       "50%       0.750000\n",
       "75%       0.750000\n",
       "max       0.750000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfCLF = RandomForestClassifier(random_state=1)\n",
    "pd.Series(cross_val_score(rfCLF, tokens_pred, y_genero, cv=10)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13.3\n",
    "\n",
    "Create a classifier to predict the industry in which each student works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.528571\n",
       "std      0.108327\n",
       "min      0.428571\n",
       "25%      0.500000\n",
       "50%      0.500000\n",
       "75%      0.500000\n",
       "max      0.714286\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "pd.Series(cross_val_score(nb, tokens_pred, y_sector, cv=5)).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
