{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QparFGCGZl4v"
   },
   "source": [
    "# Proyecto No. 3 -  Modelos Avanzados de Análisis de Datos \n",
    "\n",
    "\n",
    "### Integrantes:\n",
    "- Denis Leonardo Jaimes Campos | Código: 202027884.\n",
    "- Esteban López Zúñiga | Código: 200914313.\n",
    "- Oscar Hernando Ayala Nino | Código: 201920024.\n",
    "- Sebastián Camilo Camargo Bello | Código: 201014774.\n",
    "- Sindy Lorena Murcia Florez | Código: 202028060.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Movie Genre Classification\n",
    "\n",
    "Classify a movie genre based on its plot.\n",
    "\n",
    "<img src=\"https://github.com/dljaimes/AdvancedMethodsinDataAnalysis1Grupo_5/blob/main/moviegenre.png?raw=1\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://www.kaggle.com/c/miia4201-202019-p3-moviegenreclassification/overview\n",
    "\n",
    "### Data\n",
    "\n",
    "Input:\n",
    "- movie plot\n",
    "\n",
    "Output:\n",
    "- Probability of the movie belonging to each genre\n",
    "\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "- 50% Report with all the details of the solution, the analysis and the conclusions. The report cannot exceed 10 pages, must be send in PDF format and must be self-contained.\n",
    "- 50% Performance in the Kaggle competition (The grade for each group will be proportional to the ranking it occupies in the competition. The group in the first place will obtain 5 points, for each position below, 0.25 points will be subtracted, that is: first place: 5 points, second: 4.75 points, third place: 4.50 points ... eleventh place: 2.50 points, twelfth place: 2.25 points).\n",
    "\n",
    "\n",
    "### Deadline\n",
    "- The project must be carried out in the groups assigned.\n",
    "- Use clear and rigorous procedures.\n",
    "- The delivery of the project is on August 1st, 2021, 11:59 pm, through Bloque Neón.\n",
    "- No projects will be received after the delivery time or by any other means than the one established. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "We thank Professor Fabio Gonzalez, Ph.D. and his student John Arevalo for providing this dataset.\n",
    "\n",
    "See https://arxiv.org/abs/1702.01992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTENIDO:\n",
    "\n",
    "\n",
    "- 0. Cargue de los datos.\n",
    "- 1. Análisis Variable de repuesta.\n",
    "- 2. Limpieza y procesamiento.\n",
    "- 3. Modelamiento.\n",
    "- 4. Resultados Finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalación de librerías requeridas para el desarrollo del proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C77p01CdJu5",
    "outputId": "326f309f-9a70-4a21-ce78-d92f6d076e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting livelossplot==0.1.2\n",
      "  Downloading livelossplot-0.1.2.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from livelossplot==0.1.2) (3.3.4)\n",
      "Requirement already satisfied: notebook in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from livelossplot==0.1.2) (6.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot==0.1.2) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot==0.1.2) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot==0.1.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot==0.1.2) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot==0.1.2) (1.19.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from matplotlib->livelossplot==0.1.2) (8.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->livelossplot==0.1.2) (1.15.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (5.1.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (6.0.7)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (0.9.4)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (0.2.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (20.1.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (4.7.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (20.0.0)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (6.1.12)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (6.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (0.10.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (1.5.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (5.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (2.11.3)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from notebook->livelossplot==0.1.2) (5.3.4)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.1->notebook->livelossplot==0.1.2) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook->livelossplot==0.1.2) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook->livelossplot==0.1.2) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook->livelossplot==0.1.2) (2.20)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipykernel->notebook->livelossplot==0.1.2) (7.22.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (3.0.17)\n",
      "Requirement already satisfied: backcall in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.17.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (52.0.0.post20210125)\n",
      "Requirement already satisfied: decorator in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (5.0.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.4.4)\n",
      "Requirement already satisfied: pygments in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (2.8.1)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from jinja2->notebook->livelossplot==0.1.2) (1.1.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbconvert->notebook->livelossplot==0.1.2) (3.3.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.1.2)\n",
      "Requirement already satisfied: testpath in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbconvert->notebook->livelossplot==0.1.2) (1.4.3)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.5.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook->livelossplot==0.1.2) (1.5.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook->livelossplot==0.1.2) (1.10)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from nbformat->notebook->livelossplot==0.1.2) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->livelossplot==0.1.2) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->livelossplot==0.1.2) (0.17.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook->livelossplot==0.1.2) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sebtc\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook->livelossplot==0.1.2) (20.9)\n",
      "Building wheels for collected packages: livelossplot\n",
      "  Building wheel for livelossplot (setup.py): started\n",
      "  Building wheel for livelossplot (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created wheel for livelossplot: filename=livelossplot-0.1.2-py3-none-any.whl size=3831 sha256=9a89d2392969daa27b39b5307e689f7c998d38e24490eb7410e272d257a2681e\n",
      "  Stored in directory: c:\\users\\sebtc\\appdata\\local\\pip\\cache\\wheels\\cb\\20\\fc\\f488a78c70bd6ca8f00123a39fe239fa80ac36523908c5d298\n",
      "Successfully built livelossplot\n",
      "Installing collected packages: livelossplot\n",
      "Successfully installed livelossplot-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wordcloud\n",
    "!pip install livelossplot==0.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cxigCCrwZl40"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from livelossplot import PlotLossesKeras\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0v-sfSSdnIb",
    "outputId": "234e5350-3560-4284-be21-2e214785db26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sebtc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sebtc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Se descargan los Stopwords:\n",
    "nltk.download('stopwords')\n",
    "nltk.corpus.stopwords.words('english')\n",
    "nltk.download('wordnet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FbjuAOfcrgq"
   },
   "source": [
    "# 0. CARGUE DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z6a4eGeTZl42"
   },
   "outputs": [],
   "source": [
    "# Se cargan las bases de entrenamiento y de Prueba:\n",
    "\n",
    "dataTraining = pd.read_csv('https://github.com/albahnsen/AdvancedMethodsDataAnalysisClass/raw/master/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "dataTesting = pd.read_csv('https://github.com/albahnsen/AdvancedMethodsDataAnalysisClass/raw/master/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_amaMMQZl44",
    "outputId": "626f9496-207d-46db-b11e-a4bb26dc2bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "       year                      title  \\\n",
      "3107  2003                       Most   \n",
      "900   2008  How to Be a Serial Killer   \n",
      "\n",
      "                                                   plot  \\\n",
      "3107  most is the story of a single father who takes...   \n",
      "900   a serial killer decides to teach the secrets o...   \n",
      "\n",
      "                             genres  rating  \n",
      "3107             ['Short', 'Drama']     8.0  \n",
      "900   ['Comedy', 'Crime', 'Horror']     5.6  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Testing: \n",
      "    year                title  \\\n",
      "1  1999  Message in a Bottle   \n",
      "4  1978     Midnight Express   \n",
      "\n",
      "                                                plot  \n",
      "1  who meets by fate ,  shall be sealed by fate ....  \n",
      "4  the true story of billy hayes ,  an american c...  \n"
     ]
    }
   ],
   "source": [
    "print('Training: \\n',dataTraining.head(2))\n",
    "print('----'*30)\n",
    "print('----'*30)\n",
    "print('Testing: \\n',dataTesting.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la base consta de 7.895 registros y de 5 variables (año de la película, título, descripción (plot), género(s) y calificación). Al poder tener más de un género por película, se trata de un problema de clasificación 'Multilabel', para ello es necesario separar cada uno de los posibles géneros con sus respectivas columnas y poder entrenar en conjunto, un modelo capáz de usar el texto de la descripción de la película (plot) para predecir la probabilidad de que pertenezca a cada género."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrcnLScehg34"
   },
   "source": [
    "# 1. ANÁLISIS VARIABLE DE SALIDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ekasx5PAhgmN"
   },
   "outputs": [],
   "source": [
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x)) \n",
    "\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "SV60M3othgcL",
    "outputId": "fd6e1522-a2ce-4fd3-935e-dff600e0a07a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(y_genres, columns=le.classes_).sum().sort_values().plot(kind='bar', figsize=(18,5), grid=False, ec='black', title='DISTRIBUCIPON DE LAS CATEGORÍAS DE PELÍCULA EN LA BASE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpGzuyijjIFQ"
   },
   "source": [
    "Se observa como las categorías de Drama, Comedy, Thriller y Romance, son las que mayor participación tienen. Así mismo, las categorías de News, Short y Film-Noir presentan la menor frecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iS2ZPwWFJWYi"
   },
   "source": [
    "# 2. LIMPIEZA Y PREPROCESAMIENTO DEL TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previo a la implementación de cualquier modelo de Machine Learning, se requiere hacer una 'limpieza' sobre los datos:\n",
    "\n",
    "En esta etapa se busca eliminar los caractéres especiales así como las palabras que no agregan 'valor' al texto (stop words), todo esto con el fin de reducir el corpus (texto completo) a usar en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zgfdsc5Yb1Kz",
    "outputId": "80b9c0c6-130d-4dfb-919e-ff2a84817e8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sebtc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.corpus.stopwords.words('english')\n",
    "nltk.download('wordnet') \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer # Stemming\n",
    "from nltk.stem import WordNetLemmatizer # lemmatizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "d9WXhz2aJVa2"
   },
   "outputs": [],
   "source": [
    "# Se eliminan caracteres especiales:\n",
    "\n",
    "\n",
    "def pre_process(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    # tags\n",
    "    text = re.sub('&lt;/?.*?&gt;',' &lt;&gt; ',text)\n",
    "    # special characters and digits\n",
    "    text=re.sub('(\\\\d|\\\\W)+',' ',text)\n",
    "    # remove punctuation\n",
    "    #text = re.sub('[.;:!\\'?,\\\"()\\[\\]]', '', text)\n",
    "    #text = [REPLACE.sub('', line) for line in text]\n",
    "    \n",
    "    return text\n",
    "\n",
    "dataTraining['plot_low']=dataTraining['plot'].apply(lambda x:pre_process(x))\n",
    "dataTesting['plot_low']=dataTesting['plot'].apply(lambda x:pre_process(x))\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# se eliminan stopwords\n",
    "\n",
    "english_stop_words=stopwords.words('english')\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "dataTraining['plot_low_rm'] = remove_stop_words(dataTraining['plot_low'])\n",
    "dataTesting['plot_low_rm'] = remove_stop_words(dataTesting['plot_low'])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Stemming:\n",
    "\n",
    "\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "dataTraining['plot_low_rm_stem'] = get_stemmed_text(dataTraining['plot_low_rm'])\n",
    "dataTesting['plot_low_rm_stem'] = get_stemmed_text(dataTesting['plot_low_rm'])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# LEMATIZACION:\n",
    "\n",
    "\n",
    "def lemma(texto):\n",
    "  lemmatizador = WordNetLemmatizer()\n",
    "  return [' '.join([lemmatizador.lemmatize(word) for word in review.split()]) for review in texto]\n",
    "\n",
    "dataTraining['plot_low_rm_lemma'] = lemma(dataTraining['plot_low_rm'])\n",
    "dataTesting['plot_low_rm_lemma'] = lemma(dataTesting['plot_low_rm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "Qx6fzo3jJVRd",
    "outputId": "11eaeb74-28a2-4ea4-87a4-a959b6cd352a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "      <th>plot_low</th>\n",
       "      <th>plot_low_rm</th>\n",
       "      <th>plot_low_rm_stem</th>\n",
       "      <th>plot_low_rm_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>2003</td>\n",
       "      <td>Most</td>\n",
       "      <td>most is the story of a single father who takes...</td>\n",
       "      <td>[Short, Drama]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>most is the story of a single father who takes...</td>\n",
       "      <td>story single father takes eight year old son w...</td>\n",
       "      <td>stori singl father take eight year old son wor...</td>\n",
       "      <td>story single father take eight year old son wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2008</td>\n",
       "      <td>How to Be a Serial Killer</td>\n",
       "      <td>a serial killer decides to teach the secrets o...</td>\n",
       "      <td>[Comedy, Crime, Horror]</td>\n",
       "      <td>5.6</td>\n",
       "      <td>a serial killer decides to teach the secrets o...</td>\n",
       "      <td>serial killer decides teach secrets satisfying...</td>\n",
       "      <td>serial killer decid teach secret satisfi caree...</td>\n",
       "      <td>serial killer decides teach secret satisfying ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                      title  \\\n",
       "3107  2003                       Most   \n",
       "900   2008  How to Be a Serial Killer   \n",
       "\n",
       "                                                   plot  \\\n",
       "3107  most is the story of a single father who takes...   \n",
       "900   a serial killer decides to teach the secrets o...   \n",
       "\n",
       "                       genres  rating  \\\n",
       "3107           [Short, Drama]     8.0   \n",
       "900   [Comedy, Crime, Horror]     5.6   \n",
       "\n",
       "                                               plot_low  \\\n",
       "3107  most is the story of a single father who takes...   \n",
       "900   a serial killer decides to teach the secrets o...   \n",
       "\n",
       "                                            plot_low_rm  \\\n",
       "3107  story single father takes eight year old son w...   \n",
       "900   serial killer decides teach secrets satisfying...   \n",
       "\n",
       "                                       plot_low_rm_stem  \\\n",
       "3107  stori singl father take eight year old son wor...   \n",
       "900   serial killer decid teach secret satisfi caree...   \n",
       "\n",
       "                                      plot_low_rm_lemma  \n",
       "3107  story single father take eight year old son wo...  \n",
       "900   serial killer decides teach secret satisfying ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización de los ajustes en el texto:\n",
    "\n",
    "dataTraining.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psoasDQ7sE1O"
   },
   "source": [
    "Se observa como quedan en el dataframe las columnas con las respectivas depuraciones realizadas al texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIqdemAOcc-E"
   },
   "source": [
    "# 2. TOKENIZACIÓN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez depurado el texto de cada reseña (plot), se realiza el proceso de Tokenización para poder separar las palabras del texto y con esto, poder hacer la transformación del texto a un formato numérico, el cual es el que se usaría en la implementación de modelos.\n",
    "\n",
    "Para este caso, se evalúan tres opciones para hacer dicha transformación:\n",
    "\n",
    "- Countvectorizer(): Crea una matriz con cada palabra que se encuentre en el texto, donde cada columna corresponde a la palabra identificada y cada fila al registro del dataframe (7.895 registros).\n",
    "\n",
    "- TfidfVectorizer(): Realiza lo mismo que el anterior pero en vez de asignar valores enteros en la matriz creo porcentajes de participaci´no de cada palabra dentro del documento.\n",
    "\n",
    "- Tokenizer de Keras: Crea un diccionario de la spalabras más recurrentes, en este aparece cada palabra con su respectivo índice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtWSLLDTZl48"
   },
   "source": [
    "## 2.1 USANDO: COUNT VECTORIZER()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0esQVnU0Zl4-",
    "outputId": "c7e70e03-3660-4b16-946a-e4241ac30bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7895, 3000)\n"
     ]
    }
   ],
   "source": [
    "# Usando el countvectorizer de scikit learn:\n",
    "\n",
    "vect = CountVectorizer(max_features=3000, min_df=0.0005)\n",
    "X_dtm = vect.fit_transform(dataTraining['plot_low_rm_stem'])\n",
    "voca_coun_vec = vect.vocabulary_ # vocabulario de countvectorizer()\n",
    "\n",
    "print(X_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oNeBc8jfVVn"
   },
   "source": [
    "## 2.2. USANDO KERAS TOKENIZER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipj5mb0efUji"
   },
   "outputs": [],
   "source": [
    "tok_keras = Tokenizer(num_words=5000, oov_token='oov')\n",
    "tok_keras.fit_on_texts(dataTraining['plot_low_rm_stem'])\n",
    "vocab_keras = tok_keras.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fh0UOPRJmlM0",
    "outputId": "aef9eedd-87a2-4c9b-c21c-95ef62102a3e"
   },
   "outputs": [],
   "source": [
    "vocab_keras['singl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdI8xIfLk_1R"
   },
   "outputs": [],
   "source": [
    "# Se transforma cada texto en palabras de acuerdo con su diccionario de índices:\n",
    "\n",
    "frases_num = tok_keras.texts_to_sequences(dataTraining['plot_low_rm_stem'])\n",
    "matriz_pad =  pad_sequences(frases_num, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jMLp8A8I1CX",
    "outputId": "6e238a27-d613-4a05-d1cc-ebd49f7d8b07"
   },
   "outputs": [],
   "source": [
    "matriz_pad[1][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Usando TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vec = TfidfVectorizer(max_features=6000)\n",
    "X_tf = tf_vec.fit_transform(dataTraining['plot_low_rm_stem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranformación para la base de Testing:\n",
    "f_test = tf_vec.transform(dataTesting['plot_low_rm_stem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48SegV5Vwa9r"
   },
   "source": [
    "# ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZKM4UUswC-X"
   },
   "source": [
    "# 3. MODELAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con los textos transformados en números (paso anterior) se procede a hacer la partición de Train y test para evaluar cada uno de los posibles modelos a implementar.\n",
    "\n",
    "Ya que la matriz de variables regresoras (texto transformado en número) tiene 6 mil registros (máximo de palbras), se prevee que el entrenamiento de los modelos puede consumir bastantes recursos computacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAS-yjvXiW0P"
   },
   "source": [
    "## 3.1 PARTICION DATOS DE TRAIN Y TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3KJPe4A0Zl5C"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm.todense(), y_genres, test_size=0.33, random_state=42)\n",
    "#X_train, X_test, y_train_genres, y_test_genres = train_test_split(matriz_pad, y_genres, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9O22qFiZl5D"
   },
   "source": [
    "### Train multi-class multi-label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JDVmEbxxyJS9"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCJQrUm1pCVu"
   },
   "source": [
    "#### MODELO GAUSIANO NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Vy_eBR8PyVEp"
   },
   "outputs": [],
   "source": [
    "modelo_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "p8U7kSYZyEOp"
   },
   "outputs": [],
   "source": [
    "# Usando Naive Bayes:\n",
    "nb_c = OneVsRestClassifier(GaussianNB())\n",
    "#gbc = OneVsRestClassifier(GradientBoostingClassifier(max_depth=10,n_estimators=150,max_features=))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Yvy8dUxydft",
    "outputId": "2e0ceaac-5313-4d26-8ac5-f149ae42aa01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=GaussianNB())"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Entrenamiento modelo Naive Bayes:\n",
    "\n",
    "nb_c.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6qU2rk42bBh",
    "outputId": "03198d84-5196-4dba-ccb0-31f67be21c98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57057863950999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones modelo Naive Bayes\n",
    "\n",
    "pred_gbc = nb_c.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres, pred_gbc, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "JYgNS46s2a2N",
    "outputId": "cae2bf75-0751-405e-a52e-7e4fb89b90db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.266874e-48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.426413e-39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.613882e-102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.586012e-36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.789522e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.802275e-101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3             4    5    6              7    8    9   ...  \\\n",
       "0  1.0  1.0  0.0  0.0  0.000000e+00  1.0  0.0   9.266874e-48  1.0  1.0  ...   \n",
       "1  1.0  0.0  0.0  0.0  1.586012e-36  1.0  0.0   1.789522e-10  1.0  0.0  ...   \n",
       "2  1.0  1.0  0.0  0.0  0.000000e+00  0.0  0.0  6.802275e-101  0.0  1.0  ...   \n",
       "\n",
       "    14   15   16            17   18   19   20             21   22   23  \n",
       "0  0.0  0.0  0.0  1.426413e-39  1.0  0.0  0.0  1.613882e-102  0.0  0.0  \n",
       "1  0.0  1.0  0.0  1.000000e+00  0.0  0.0  0.0   1.000000e+00  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.000000e+00  1.0  0.0  0.0   1.000000e+00  0.0  0.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred_gbc).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa como el modelo da como salida una matriz de 24 columnas (una por cada categoría) en la que se registran las probabilidades de que cada película (fila) pertenezca a dicha categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PufjBN_Jy5r1",
    "outputId": "a9d631c7-e64e-45cb-8920-765efc9c4d60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57057863950999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nb = nb_c.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres, pred_nb, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdCU_B0x8as6"
   },
   "source": [
    "El modelo arroja como resultado un AUC de 0.65 para los datos de test (datos que nuevos para el modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPHCTH828cpr"
   },
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la cantidad de columnas de la matriz de entrada (X), se optó por hacer el Tune-In de este modelo de manera manual, para ello, se corría el modelo con ciertos hiperparámetros predeterminados, calculando el AUC y luego se volviendo a correr el modelo cambiando los hiperparámetros  (básicamente, una validación manual de lo que realiza una grilla)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6tfcdPQ8jcT"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aU2DvIV9d-F"
   },
   "outputs": [],
   "source": [
    "xgb = OneVsRestClassifier(XGBClassifier(random_state=42,n_estimators=200, learning_rate=0.3, max_depth=7))\n",
    "xgb.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDUWaVRx-aS7",
    "outputId": "d53abda9-b7d4-4ead-b162-201c315d6ada"
   },
   "outputs": [],
   "source": [
    "y_pred_genresxg = xgb.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres, y_pred_genresxg, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "XcMWyQ7aC2V1",
    "outputId": "a039e5eb-8a39-4c5a-b4f9-c440416b3865"
   },
   "outputs": [],
   "source": [
    "####################### resultados usando COUNTVETORIZER() y Lemma:\n",
    "-------- Para un número de palabras = 5 mil\n",
    "\n",
    "learning rate =0.1, n_jobs=1, n_estimators=100, max_depth=3, random_state=42  : 0.8391366613062118\n",
    "learning rate =0.1, n_jobs=1, n_estimators=200, max_depth=3, random_state=42  : 0.8379697098500808\n",
    "learning rate =0.3, n_jobs=1, n_estimators=100, max_depth=5, random_state=42  : 0.8434843032865246\n",
    "learning rate =0.3, n_jobs=1, n_estimators=200, max_depth=5, random_state=42  : 0.8434843032865246\n",
    "learning rate =0.3, n_jobs=1, n_estimators=100, max_depth=7, random_state=42  : 0.8403513018075838\n",
    "learning rate =0.3, n_jobs=1, n_estimators=100, max_depth=3, random_state=42  : 0.8418200586529831\n",
    "learning rate =0.3, n_jobs=1, n_estimators=200, max_depth=3, random_state=42  : 0.8379697098500808\n",
    "learning rate =0.5, n_jobs=1, n_estimators=100, max_depth=3, random_state=42  : 0.834508059445182\n",
    "learning rate =0.5, n_jobs=1, n_estimators=200, max_depth=3, random_state=42  : 0.8334327736298276\n",
    "\n",
    "-------- Para un número de palabras =  3mil\n",
    "learning rate =0.1, n_jobs=1, n_estimators=100, max_depth=3, random_state=42  : 0.8278829167399256\n",
    "learning rate =0.1, n_jobs=1, n_estimators=200, max_depth=3, random_state=42  : 0.8371912538301466\n",
    "learning rate =0.3, n_jobs=1, n_estimators=500, max_depth=3, random_state=42  : 0.8232835712614154\n",
    "learning rate =0.1, n_jobs=1, n_estimators=200, max_depth=5, random_state=42  : 0.8354213500350042\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " El mejor modelo se obtiene con el valor de AUC de 0.8434\n",
    " \n",
    " learning rate =0.3, n_jobs=1, n_estimators=200, max_depth=5, random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YzzgqlTi7l0"
   },
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(dataTesting['plot_low_rm_stem'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = xgb.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy0WfpMdi8bq"
   },
   "source": [
    "# GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que el XGBoost, el Tune In se realiza de manera manual ya que al intentar hacerlo por grilla, se consume bastantes recursos computacionales (muchísimo tiempo para calibrar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvOK0IyrjBdT"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQ6txK6NjMnM",
    "outputId": "07adfd6b-b2ef-4c80-e687-3d00af976ba8"
   },
   "outputs": [],
   "source": [
    "gb = OneVsRestClassifier(GradientBoostingClassifier(random_state=42,n_estimators=200))\n",
    "gb.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1PFAHOXjV2y",
    "outputId": "19c89395-0868-454e-c4f8-dfb69a41f18f"
   },
   "outputs": [],
   "source": [
    "y_pred_genresgb = gb.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres, y_pred_genresgb, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caouOcBMtlDz"
   },
   "outputs": [],
   "source": [
    "####################### resultados usando COUNTVETORIZER() y Lemma:\n",
    "-------- Para un número de palabras = 3 mil\n",
    "\n",
    "learning rate =0.1, n_jobs=1, n_estimators=100, max_depth=3, random_state=42  : 0.791546841465498\n",
    "learning rate =0.1, n_jobs=1, n_estimators=200, max_depth=3, random_state=42  : 0.7919201382227256\n",
    "learning rate =0.1, n_jobs=1, n_estimators=200, max_depth=5, random_state=42  : 0.7945468422746468\n",
    "\n",
    "-------- Para un número de palabras = 5 mil\n",
    "\n",
    "learning rate =0.1, n_jobs=1, n_estimators=200, max_depth=3, random_state=42  : 0.7946901445030538\n",
    "learning rate =0.1, n_jobs=1, n_estimators=200, max_depth=5, random_state=42  : 0.8045030538546875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xqre40mo3R4U"
   },
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(dataTesting['plot_low_rm_stem'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = gb.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkMQn8ROslw6"
   },
   "source": [
    "No se observa un valor que mejor el XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WofOmCF2R9BK"
   },
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xm-0YX09Zl5E"
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=500, max_depth=5, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuOMKMiMhtqd",
    "outputId": "85fe884a-8d8a-4355-fecd-3af2992e8140"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf.fit(X_train, y_train_genres);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJtEnbNcZl5F",
    "outputId": "76963d53-e6ce-40d8-bfe7-d1ea6eb2b6bc"
   },
   "outputs": [],
   "source": [
    "y_pred_genres = clf.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qedKW88piQbc"
   },
   "outputs": [],
   "source": [
    "####################### resultados usando COUNTVETORIZER() y Lemma:\n",
    "\n",
    "\"\"\"\n",
    "------- Para un número de palabras = 1 mil\n",
    "\n",
    "n_jobs=-1, n_estimators=200, max_depth=7, random_state=42 : 0.7872131570577036\n",
    "n_jobs=-1, n_estimators=200, max_depth=10, random_state=42 : 0.7840666999257996\n",
    "n_jobs=-1, n_estimators=250, max_depth=7, random_state=42 : 0.7901943042466396\n",
    "n_jobs=-1, n_estimators=250, max_depth=7, random_state=42 : 0.7908025199296361\n",
    "n_jobs=-1, n_estimators=500, max_depth=7, random_state=42 : 0.7931854788836633\n",
    "n_jobs=-1, n_estimators=500, max_depth=5, random_state=42 : 0.7934482357988548\n",
    "n_jobs=-1, n_estimators=700, max_depth=3, random_state=42 : 0.7926350713330667\n",
    "n_jobs=-1, n_estimators=500, max_depth=3, random_state=42 : 0.7918581885906483\n",
    "n_jobs=-1, n_estimators=500, max_depth=4, random_state=42 : 0.7916051690107286\n",
    "\n",
    "\n",
    "------- Para un número de palabras = 3 mil\n",
    "\n",
    "n_jobs=-1, n_estimators=500, max_depth=5, random_state=42 : 0.8105434607387648\n",
    "-------- Para un número de palabras = 5 mil\n",
    "\n",
    "n_jobs=-1, n_estimators=500, max_depth=5, random_state=42  : 0.8203351605539488\n",
    "\n",
    "\"\"\"\n",
    "################## resultados usando COUNTVETORIZER() y Stemm:\n",
    "\"\"\"\n",
    "-------- Para un número de palabras = 5 mil\n",
    "\n",
    "n_jobs=-1, n_estimators=500, max_depth=5, random_state=42  : 0.8238489387536768\n",
    "\"\"\"\n",
    "################## resultados usando COUNTVETORIZER(ngram_range=range(1,2)) y Stemm:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "n_jobs=-1, n_estimators=500, max_depth=5, random_state=42  : 0.8204102576175692\n",
    "\n",
    "\"\"\"\n",
    "########### resultados countvetorizer(min_df=0.2,max_features=5000 ) y stemma:\n",
    "\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbSdJySo6oDk"
   },
   "outputs": [],
   "source": [
    "X_dtm_test =  vect.transform(dataTesting['plot_low_rm_stem'])\n",
    "X_dtm_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EN4PJ76nzPsi"
   },
   "outputs": [],
   "source": [
    "# Predicciones en la base de Testing:\n",
    "\n",
    "pred_test_rf = clf.predict_proba(X_dtm_test)\n",
    "pred_test_rf = pd.DataFrame(pred_test_rf)\n",
    "pred_test_rf.columns = ['p_'+i for i in le.classes_]\n",
    "pred_test_rf.index= dataTesting.index\n",
    "pred_test_rf.to_csv('pred_test_rf_5mil_dep5_nst500_counvec_stemm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYXWy2YV7EWD"
   },
   "source": [
    "Se observan valores superiores a los del Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Whuz6ZTm0IOD"
   },
   "source": [
    "## RED NEURONAL - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d84CEpdczPhy"
   },
   "outputs": [],
   "source": [
    "x = dataTraining['plot_low_rm_stem'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max len\n",
    "max_tokens = 500\n",
    "X = [x.split()[:max_tokens] for x in x]\n",
    "\n",
    "# Usando el vacobulario de countvectorizer:\n",
    "\n",
    "\n",
    "# Convert characters to int and pad\n",
    "X_2 = [[voca_coun_vec[x1] for x1 in x if x1 in voca_coun_vec.keys()] for x in X]\n",
    "\n",
    "# Ahaora se usa el pad_sequence de Keras:\n",
    "X_pad_keras = pad_sequences(X_2, maxlen=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partición de los datos para entrenar la Red:\n",
    "\n",
    "X_train_red, X_test_red, y_train_genres_red, y_test_genres_red = train_test_split(X_pad_keras, df_genre['Adventure'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelamiento de la Red usando un esquema de LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(voca_coun_vec) + 1, 128, input_length=max_tokens))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Se especifica la función de pérdida, optimizador y la métrica de evaluación\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['AUC'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Entrenamiento de la RED:\n",
    "\n",
    "model.fit(X_train_red, y_train_genres_red, validation_data=[X_test_red, y_test_genres_red], \n",
    "          batch_size=64, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeBpTUPKZl5G"
   },
   "source": [
    "El Tune in también se realiza manual unque en este caso, la calibración delo modelo tomó muchísimo más tiempo (4 horas para 10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTADOS EN LA RED :\n",
    "\n",
    "# Modelo por defecto:\n",
    "\n",
    "# Modelo:\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(voca_coun_vec) + 1, 128, input_length=max_tokens))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(24, activation='sigmoid'))\n",
    "\n",
    "\n",
    "auc_score = 0.6567200841337979\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "## Se cambio LSTM a 128:\n",
    "\n",
    "\"\"\"\n",
    "auc_score = 0.7000371246853678\n",
    "\"\"\"\n",
    "\n",
    "## Se incluyó el Bidirectional al LSTM y se agregó una capa previa a la capa de salida y se cambia la métrica a AUC:\n",
    "\n",
    "\"\"\"  auc_score= 0.7444601125448411 \"\"\"\n",
    "\n",
    "\n",
    "## Se agregan dos Bidirecionales: la 1ra con una capa de :\n",
    "\n",
    "\"\"\"  auc_scoer= 0.6131181703975308  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que los resultados no son los más indicados ya que se encuentran por debajo de lo obtenido en los otros modelos.\n",
    "\n",
    "Es de aclarar que se usaron pocos epochs lo cual hace que la red no calibre en su totalidad, sin embargo, al aumentor estos últimos, el tiempo de entrenamiento aumenta drásticamente razón por la que no se pudo obtener un resultado satisfactorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byxErouiZl5I"
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "YA4lQJbpZl5J",
    "outputId": "acbf4616-baa8-4918-8747-d5b1cf876fb2"
   },
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBSszOpdZl5L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6baFFX1ezIOO"
   },
   "source": [
    "# 4. RESULTADOS FINALES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al presentar diferentes resultados por los modelos evaluados, se optó por hacer un modelo de stacking con los resultados iniciales obtenidos por los modelos de Random Forest, para ello se usó un modelo de Regresión logística sobre estos resultados, mejorando los resultados obtenidos en la competencia (auc_score= 0.8592 - Cargado por Sebastian.Camargo) \n",
    "<br>Como estrategia definimos usar las probabilidades de salida de los modelos como variables predictoras en un modelo de regresión logistica encontrando que:\n",
    "<br> - El modelo bayesiano con regresión logistica mejora bastante en el conjunto de train, pero su desempeño en conjunto test se mantiene bajo.\n",
    "<br> - El modelo de Random forest con regresión logistica mejora tanto en train como en test postulandose como la mejor opción.\n",
    "<br> - El modelo de XGBoost con regresión logistica mantiene muy buen AUC en el conjunto de train, en el conjunto de test tiene buen desempeño pero se ve superado por el modelo de RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC en train: 0.8997157155450219\n",
      "ROC en test: 0.57057863950999\n",
      "ROC en train con stacking: 0.949044297171428\n",
      "ROC en test con stacking: 0.6748318354727827\n"
     ]
    }
   ],
   "source": [
    "#Modelo naive bayesiano\n",
    "nb_c = OneVsRestClassifier(GaussianNB())\n",
    "nb_c.fit(X_train, y_train_genres)\n",
    "\n",
    "nb_c_pred_train = nb_c.predict_proba(X_train)\n",
    "nb_c_pred_test  = nb_c.predict_proba(X_test)\n",
    "\n",
    "print(\"ROC en train:\",roc_auc_score(y_train_genres, nb_c_pred_train, average='macro'))\n",
    "print(\"ROC en test:\" ,roc_auc_score(y_test_genres,  nb_c_pred_test,  average='macro'))\n",
    "\n",
    "#Stacking sobre naive bayesiano\n",
    "stack_logit_nb = OneVsRestClassifier(LogisticRegression(n_jobs=-1))\n",
    "stack_logit_nb.fit(nb_c_pred_train, y_train_genres)\n",
    "stack_logit_nb_pred_train = stack_logit_nb.predict_proba(nb_c_pred_train)\n",
    "stack_logit_nb_pred_test = stack_logit_nb.predict_proba(nb_c_pred_test)\n",
    "print(\"ROC en train con stacking:\",roc_auc_score(y_train_genres, stack_logit_nb_pred_train, average='macro'))\n",
    "print(\"ROC en test con stacking:\",roc_auc_score(y_test_genres, stack_logit_nb_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC en train: 0.9294125351902108\n",
      "ROC en test: 0.8100366313314673\n",
      "ROC en train con stacking: 0.9252527510594056\n",
      "ROC en test con stacking: 0.847021247266808\n"
     ]
    }
   ],
   "source": [
    "#Modelo Random forest classifier\n",
    "rf_c = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=500, max_depth=5, random_state=42))\n",
    "rf_c.fit(X_train, y_train_genres)\n",
    "\n",
    "rf_c_pred_train = rf_c.predict_proba(X_train)\n",
    "rf_c_pred_test  = rf_c.predict_proba(X_test)\n",
    "\n",
    "print(\"ROC en train:\", roc_auc_score(y_train_genres, rf_c_pred_train, average='macro'))\n",
    "print(\"ROC en test:\",  roc_auc_score(y_test_genres,  rf_c_pred_test,  average='macro'))\n",
    "\n",
    "#Stacking sobre random forest\n",
    "stack_logit_rf = OneVsRestClassifier(LogisticRegression(n_jobs=-1))\n",
    "stack_logit_rf.fit(rf_c_pred_train, y_train_genres)\n",
    "stack_logit_rf_pred_train = stack_logit_rf.predict_proba(rf_c_pred_train)\n",
    "stack_logit_rf_pred_test = stack_logit_rf.predict_proba(rf_c_pred_test)\n",
    "print(\"ROC en train con stacking:\",roc_auc_score(y_train_genres, stack_logit_rf_pred_train, average='macro'))\n",
    "print(\"ROC en test con stacking:\",roc_auc_score(y_test_genres, stack_logit_rf_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo XGBoost\n",
    "xgb_c = OneVsRestClassifier(XGBClassifier(random_state=42,n_estimators=100, learning_rate=0.3, max_depth=7,verbosity=0))\n",
    "xgb_c.fit(X_train, y_train_genres)\n",
    "\n",
    "xgb_c_pred_train = xgb_c.predict_proba(X_train)\n",
    "xgb_c_pred_test  = xgb_c.predict_proba(X_test)\n",
    "\n",
    "print(\"ROC en train:\", roc_auc_score(y_train_genres, xgb_c_pred_train, average='macro'))\n",
    "print(\"ROC en test:\",  roc_auc_score(y_test_genres,  xgb_c_pred_test,  average='macro'))\n",
    "\n",
    "#Stacking sobre XGBooost\n",
    "stack_logit_xgb = OneVsRestClassifier(LogisticRegression(n_jobs=-1))\n",
    "stack_logit_xgb.fit(xgb_c_pred_train, y_train_genres)\n",
    "stack_logit_xgb_pred_train = stack_logit_xgb.predict_proba(xgb_c_pred_train)\n",
    "stack_logit_xgb_pred_test = stack_logit_xgb.predict_proba(xgb_c_pred_test)\n",
    "print(\"ROC en train con stacking::\",roc_auc_score(y_train_genres, stack_logit_xgb_pred_train, average='macro'))\n",
    "print(\"ROC en test con stacking::\",roc_auc_score(y_test_genres, stack_logit_xgb_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos tambien la combinación de mas de un modelo en el stacking, por ello dispusimos como variables predictoras tanto las predicciones del Random forest como las predicciones del XGBoost; encontramos que en el conjunto de train alcanza un AUC muy cercano a 100% pero en el conjunto de Test es inferior al modelo de stacking que solo relaciona Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking sobre random forest & XGBoost\n",
    "rf_xgb_pred_train = np.c_[rf_c_pred_train,xgb_c_pred_train]\n",
    "rf_xgb_pred_test = np.c_[rf_c_pred_test,xgb_c_pred_test]\n",
    "\n",
    "stack_logit_rf_xgb = OneVsRestClassifier(LogisticRegression(n_jobs=-1))\n",
    "stack_logit_rf_xgb.fit(rf_xgb_pred_train, y_train_genres)\n",
    "stack_logit_rf_xgb_pred_train = stack_logit_rf_xgb.predict_proba(rf_xgb_pred_train)\n",
    "stack_logit_rf_xgb_pred_test = stack_logit_rf_xgb.predict_proba(rf_xgb_pred_test)\n",
    "print(\"ROC en train:\",roc_auc_score(y_train_genres, stack_logit_rf_xgb_pred_train, average='macro'))\n",
    "print(\"ROC en test:\",roc_auc_score(y_test_genres, stack_logit_rf_xgb_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se elige como mejor opción el modelo de Random Forest & Regresión logistica, con el cual se prepara el archivo de predicciones para llevar a la competencia de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC en train: 0.8899589646091322\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Modelo Random forest classifier sobre el total de datos disponibles\n",
    "rf_c_ttl = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=500, max_depth=5, random_state=42))\n",
    "rf_c_ttl.fit(X_dtm.todense(), y_genres)\n",
    "\n",
    "rf_c_ttl_pred_train = rf_c.predict_proba(X_dtm.todense())\n",
    "\n",
    "print(\"ROC en train:\", roc_auc_score(y_genres, rf_c_ttl_pred_train, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC en train: 0.9002881646731945\n"
     ]
    }
   ],
   "source": [
    "#Stacking sobre solo random forest\n",
    "\n",
    "stack_logit_rf_ttl = OneVsRestClassifier(LogisticRegression(n_jobs=-1))\n",
    "stack_logit_rf_ttl.fit(rf_c_ttl_pred_train, y_genres)\n",
    "\n",
    "stack_logit_rf_ttl_pred_train = stack_logit_rf_ttl.predict_proba(rf_c_ttl_pred_train)\n",
    "\n",
    "print(\"ROC en train:\",roc_auc_score(y_genres, stack_logit_rf_ttl_pred_train, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluacion base test para Kaggle\n",
    "X_dtm_test =  vect.transform(dataTesting['plot_low_rm_stem'])\n",
    "\n",
    "rf_c_ttl_pred_test_ext   = rf_c.predict_proba(X_dtm_test.todense())\n",
    "\n",
    "stack_logit_rf_ttl_pred_test_ext = stack_logit_rf_ttl.predict_proba(rf_c_ttl_pred_test_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = pd.DataFrame(stack_logit_rf_ttl_pred_test_ext)\n",
    "pred_file.columns = ['p_'+i for i in le.classes_]\n",
    "pred_file.shape\n",
    "pred_file.index= dataTesting.index\n",
    "pred_file\n",
    "pred_file.to_csv('file_competencia.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de Proyecto_3_Leo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
